{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import yaml\n",
    "import json\n",
    "from tensorflow.python.tools import saved_model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT='surface-water-278805'\n",
    "OUTPUT_BAND='water'\n",
    "CONFIG={\n",
    "    'autoScaling': { 'minNodes': 10 }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NAME='xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215'\n",
    "RUN='sw_r7'\n",
    "MODEL_NAME='xception_seg_long'\n",
    "VERSION=1\n",
    "IS_NEW_MODEL=False\n",
    "DRY_RUN=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEIFY_CMD=(\n",
    "    \"earthengine model prepare --source_dir {} --dest_dir {} \"\n",
    "    \"--input \\'{}\\' --output \\'{}\\'\" )\n",
    "\n",
    "CREATE_MODEL_CMD='gcloud ai-platform models create {} --project {}'\n",
    "\n",
    "CREATE_VERSION_CMD=(\n",
    "    'gcloud ai-platform versions create {} '\n",
    "        '--project {} '\n",
    "        '--model {} '\n",
    "        '--origin {} '\n",
    "        '--framework \"TENSORFLOW\" '\n",
    "        '--runtime-version 2.1 '\n",
    "        '--python-version 3.7 '\n",
    "        '--config={}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_YAML_FILE='_config.tmp.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_yaml(destination_yaml_file,**kwargs):\n",
    "    with open(destination_yaml_file, 'w') as file:\n",
    "        documents = yaml.dump(kwargs, file)\n",
    "\n",
    "        \n",
    "def _process_cmd(cmd,description='run',dry_run=False):\n",
    "    print(f'{description}:',cmd)\n",
    "    if not dry_run:\n",
    "        result=subprocess.run([cmd], stdout=subprocess.PIPE, shell=True)\n",
    "        print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(model_name,run_folder,version=1,is_dev=False):\n",
    "    src=f'gs://sw-ai-platform/{run_folder}/output/{model_name}/model'\n",
    "    if isinstance(version,int):\n",
    "        version=f'v{version}'\n",
    "    dest='gs://gee-models/models'\n",
    "    if is_dev:\n",
    "        dest=f'dest/{dev}'\n",
    "    dest=f'{dest}/{model_name}/{version}'\n",
    "    return src, dest, version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeify(src_dir,dest_dir,output_band=OUTPUT_BAND,dry_run=DRY_RUN):\n",
    "    meta_graph_def = saved_model_utils.get_meta_graph_def(src_dir, 'serve')\n",
    "    inputs=meta_graph_def.signature_def['serving_default'].inputs\n",
    "    outputs=meta_graph_def.signature_def['serving_default'].outputs\n",
    "    input_dict={ next(iter(inputs.values())).name: \"array\" }\n",
    "    output_dict={ next(iter(outputs.values())).name: output_band }\n",
    "    print('-'*100)\n",
    "    cmd=EEIFY_CMD.format(src_dir,dest_dir,json.dumps(input_dict),json.dumps(output_dict))\n",
    "    _process_cmd(cmd,description='eeifying model',dry_run=dry_run)\n",
    "    print('-'*100)\n",
    "    \n",
    "\n",
    "def create_model(model_name,project=PROJECT,dry_run=DRY_RUN):\n",
    "    cmd=CREATE_MODEL_CMD.format(model_name,project)\n",
    "    _process_cmd(cmd,description='create model',dry_run=dry_run)\n",
    "        \n",
    "        \n",
    "def create_version(model_name,model_dir,version,config=CONFIG,project=PROJECT,dry_run=DRY_RUN):\n",
    "    _write_yaml(TMP_YAML_FILE,**config)\n",
    "    cmd=CREATE_VERSION_CMD.format(version,project,model_name,model_dir,TMP_YAML_FILE)\n",
    "    _process_cmd(cmd,description='create version',dry_run=dry_run)\n",
    "    os.remove(TMP_YAML_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "src: gs://sw-ai-platform/sw_r7/output/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/model\n",
      "geeified: gs://gee-models/models/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/v1\n",
      "model: xception_seg_long\n",
      "model_version: v1\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "src_dir, ee_dir, version=get_dirs(TRAIN_NAME,RUN,VERSION)\n",
    "print('-'*100)\n",
    "print('src:',src_dir)\n",
    "print('geeified:',ee_dir)\n",
    "print('model:',MODEL_NAME)\n",
    "print('model_version:',version)\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "eeifying model: earthengine model prepare --source_dir gs://sw-ai-platform/sw_r7/output/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/model --dest_dir gs://gee-models/models/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/v1 --input '{\"serving_default_input:0\": \"array\"}' --output '{\"StatefulPartitionedCall:0\": \"water\"}'\n",
      "Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n",
      "\n",
      "Success: model at 'gs://gee-models/models/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/v1' is ready to be hosted in AI Platform.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eeify(src_dir,ee_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NEW_MODEL:\n",
    "    create_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create version: gcloud ai-platform versions create v1 --project surface-water-278805 --model xception_seg_long --origin gs://gee-models/models/xception-xception_seg_long.wcce-fromlogits-lsmooth0p1_20200707_052215/v1 --framework \"TENSORFLOW\" --runtime-version 2.1 --python-version 3.7 --config=_config.tmp.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_version(MODEL_NAME,ee_dir,version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
