{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-T0bLcqEPsH_"
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5LA_hYb3flk"
   },
   "outputs": [],
   "source": [
    "import tfr2human.parser as tfp\n",
    "import tfr2human.utils as utils\n",
    "import gcs_helpers.save as gsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRIR6bZoCMtZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION=10\n",
    "SIZE=192\n",
    "NOISY=True\n",
    "NOISE_REDUCER=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBh_U14UZOPJ"
   },
   "outputs": [],
   "source": [
    "VERSION=1\n",
    "# update to use tfrecords of interest\n",
    "SRC_FOLDER='global-high-water'\n",
    "TFR_SELECTOR=f'gs://surface-water-public/gee-exports/TFR/{SRC_FOLDER}/*.tfrecord.gz'\n",
    "# update destination folder/bucket\n",
    "GCS_BUCKET='surface-water-public'\n",
    "GCS_FOLDER=f'data/{SRC_FOLDER}/v{VERSION}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "DMHeikNt4gFy",
    "outputId": "a74c35f2-11c0-4af0-a242-f025cd7bb686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFR_LIST = tf.io.gfile.glob(TFR_SELECTOR)\n",
    "len(TFR_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkPp4puhfG2c"
   },
   "outputs": [],
   "source": [
    "WATER_BANDS=['gsw']\n",
    "S1_BANDS=['VV','VH','angle','VV_mean','VH_mean']\n",
    "BANDS=S1_BANDS+WATER_BANDS\n",
    "\n",
    "FEATURE_PROPS={\n",
    "    'aoi': tf.string,\n",
    "    'block_id': tf.string,\n",
    "    'group_id': tf.string,\n",
    "    'lon_id': tf.string,\n",
    "    'lat_id': tf.string,\n",
    "    'water_score': tf.float32,\n",
    "    'water': tf.float32,\n",
    "    'no_data': tf.float32,\n",
    "    'not_water': tf.float32,\n",
    "    'crs': tf.string,\n",
    "    'utm': tf.string,\n",
    "    'nsh': tf.string,\n",
    "    'ewh': tf.string,\n",
    "    'year': tf.float32,\n",
    "    'month': tf.float32,\n",
    "    'date': tf.string,\n",
    "    'lon': tf.float32,\n",
    "    'lat': tf.float32,\n",
    "    'biome_name': tf.string,\n",
    "    'biome_num': tf.float32,\n",
    "    'eco_id': tf.float32,\n",
    "    'eco_name': tf.string,\n",
    "    'nnh': tf.float32,\n",
    "    'nnh_name': tf.string,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU8utr92BF4L"
   },
   "outputs": [],
   "source": [
    "WATER_COLUMNS={\n",
    "    0: 'no_data_pixel_count',\n",
    "    1: 'not_water_pixel_count',\n",
    "    2: 'water_pixel_count'\n",
    "}\n",
    "\n",
    "\n",
    "def process_water(parser,element):\n",
    "    water=parser.image(element,bands=WATER_BANDS,dtype=np.uint8)\n",
    "    values,counts=np.unique(water,return_counts=True)\n",
    "    props={v: c for (v,c) in zip(values,counts)}\n",
    "    props={WATER_COLUMNS[i]: props.get(i,0) for i in range(3)}\n",
    "    if props['not_water_pixel_count']:\n",
    "        props['water_ratio']=props['water_pixel_count']/props['not_water_pixel_count']\n",
    "    else:\n",
    "        props['water_ratio']=1\n",
    "    return water, props\n",
    "\n",
    "\n",
    "def process_s1(parser,element):\n",
    "    s1=parser.image(element,bands=S1_BANDS,dtype=np.float32)\n",
    "    props={ \n",
    "        's1_na_pixel_count': np.count_nonzero(np.isnan(s1)),\n",
    "        '-': np.count_nonzero((s1[0]*s1[1])==0),\n",
    "    }\n",
    "    return s1, props\n",
    "\n",
    "\n",
    "def image_name(lon_id,lat_id,year,month):\n",
    "    name=f'tile_{lon_id}_{lat_id}'\n",
    "    return f'{name}-{int(year)}{str(int(month)).zfill(2)}.tif'\n",
    "\n",
    "DEFAULT_BATCH_SIZE=100\n",
    "\n",
    "def run(parser,take=40,skip=0,batch_size=DEFAULT_BATCH_SIZE):\n",
    "    \"\"\" example:\n",
    "        - parse all data properties (note: you could have also passed `keys` to `.data()` for a subset of properties )\n",
    "        - parse bands into distinct images\n",
    "    \"\"\"\n",
    "    parsed_data=parser.dataset.skip(skip)\n",
    "    if take:\n",
    "        parsed_data=parsed_data.take(take)\n",
    "    for batch_index, batch in utils.get_batches(parsed_data,batch_size=batch_size):\n",
    "        print('\\n'*2)\n",
    "        print('='*75)\n",
    "        batch_index=batch_index+int(skip/batch_size)+1\n",
    "        print('BATCH:',batch_index)\n",
    "        print('='*75)\n",
    "        rows=[]\n",
    "        try:\n",
    "            for i,element in enumerate(batch):\n",
    "                props=parser.data(element)\n",
    "                if NOISY and (not (i%NOISE_REDUCER)): \n",
    "                    print(f'\\t- {i} [{props[\"aoi\"]}, {props[\"date\"]}]...')\n",
    "                water, water_props=process_water(parser,element)\n",
    "                s1, s1_props=process_s1(parser,element)\n",
    "                props.update(water_props)\n",
    "                props.update(s1_props)\n",
    "                rows.append(props)\n",
    "                # export images\n",
    "                lon=props['lon']\n",
    "                lat=props['lat']\n",
    "                crs=props['crs']\n",
    "                name=image_name(\n",
    "                    lon_id=props['lon_id'],\n",
    "                    lat_id=props['lat_id'],\n",
    "                    year=props['year'],\n",
    "                    month=props['month'])\n",
    "                gsave.image(\n",
    "                  s1,\n",
    "                  name,\n",
    "                  utils.image_profile(lon,lat,crs,RESOLUTION,s1),\n",
    "                  folder=f'{GCS_FOLDER}/S1',\n",
    "                  bucket=GCS_BUCKET)\n",
    "                gsave.image(\n",
    "                  water,\n",
    "                  name,\n",
    "                  utils.image_profile(lon,lat,crs,RESOLUTION,water),\n",
    "                  folder=f'{GCS_FOLDER}/GSW',\n",
    "                  bucket=GCS_BUCKET)\n",
    "            df=pd.DataFrame(rows)\n",
    "            gcs_path=gsave.csv(\n",
    "              df,\n",
    "              f'EXPORTS_BATCH-{batch_index}.csv',\n",
    "              folder=f'{GCS_FOLDER}/CSV',\n",
    "              bucket=GCS_BUCKET)\n",
    "            print('-'*75)\n",
    "            print(gcs_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('\\n'*2)\n",
    "            print(\"FAILURE:\")\n",
    "            print(str(e))\n",
    "            print()\n",
    "            print(i, batch)\n",
    "            print()\n",
    "            pprint(props)\n",
    "            print('\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "93YjQmp9I36V",
    "outputId": "adcaf699-ceb3-4512-f401-c1b79296c372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TAKE: None BATCH_SIZE: 500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "['VV', 'VH', 'angle', 'VV_mean', 'VH_mean', 'gsw']\n",
      "\n",
      "{'aoi': tf.string,\n",
      " 'biome_name': tf.string,\n",
      " 'biome_num': tf.float32,\n",
      " 'block_id': tf.string,\n",
      " 'crs': tf.string,\n",
      " 'date': tf.string,\n",
      " 'eco_id': tf.float32,\n",
      " 'eco_name': tf.string,\n",
      " 'ewh': tf.string,\n",
      " 'group_id': tf.string,\n",
      " 'lat': tf.float32,\n",
      " 'lat_id': tf.string,\n",
      " 'lon': tf.float32,\n",
      " 'lon_id': tf.string,\n",
      " 'month': tf.float32,\n",
      " 'nnh': tf.float32,\n",
      " 'nnh_name': tf.string,\n",
      " 'no_data': tf.float32,\n",
      " 'not_water': tf.float32,\n",
      " 'nsh': tf.string,\n",
      " 'utm': tf.string,\n",
      " 'water': tf.float32,\n",
      " 'water_score': tf.float32,\n",
      " 'year': tf.float32}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "BATCH: 1\n",
      "===========================================================================\n",
      "\t- 0 [africa_central, 2015-01-01]...\n",
      "\t- 10 [africa_central, 2015-01-01]...\n",
      "\t- 20 [africa_central, 2015-01-01]...\n",
      "\t- 30 [africa_central, 2015-01-01]...\n",
      "\t- 40 [africa_central, 2015-01-01]...\n",
      "\t- 50 [africa_central, 2015-01-01]...\n",
      "\t- 60 [africa_central, 2015-01-01]...\n",
      "\t- 70 [africa_central, 2015-01-01]...\n",
      "\t- 80 [africa_central, 2015-01-01]...\n"
     ]
    }
   ],
   "source": [
    "tfp=reload(tfp)\n",
    "\n",
    "\"\"\" interuppted after batch 4:\n",
    "TAKE=None\n",
    "SKIP=0\n",
    "BATCH_SIZE=500\n",
    "\"\"\"\n",
    "\n",
    "TAKE=None\n",
    "BATCH_SIZE=500\n",
    "SKIP=0\n",
    "\n",
    "# TAKE=None\n",
    "# BATCH_SIZE=5\n",
    "# SKIP=4*BATCH_SIZE\n",
    "\n",
    "print('\\n'*2)\n",
    "print('-'*100)\n",
    "print('TAKE:',TAKE,'BATCH_SIZE:',BATCH_SIZE)\n",
    "print('-'*100)\n",
    "print()\n",
    "pprint(BANDS)\n",
    "print()\n",
    "pprint(FEATURE_PROPS)\n",
    "print()\n",
    "print('-'*100)\n",
    "print('\\n'*2)\n",
    "\n",
    "\n",
    "parser=tfp.TFRParser(\n",
    "    TFR_LIST,\n",
    "    specs=FEATURE_PROPS,\n",
    "    band_specs=BANDS,\n",
    "    dims=[SIZE,SIZE])\n",
    "\n",
    "\n",
    "run(parser,take=TAKE,skip=SKIP,batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### INSPECT MASTER DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TMPL='https://storage.googleapis.com/surface-water-public/data/global-high-water/v1/CSV/EXPORTS_BATCH-{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([pd.read_csv(URL_TMPL.format(i)) for i in range(1,35)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLS=[\n",
    "    'water',\n",
    "    'water_pixel_count',\n",
    "    'water_ratio',\n",
    "    'not_water',\n",
    "    'not_water_pixel_count',\n",
    "    'no_data',\n",
    "    'no_data_pixel_count',\n",
    "    's1_zero_pixel_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[DATA_COLS].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PIXELS=192**2\n",
    "MAX_NO_DATA=NB_PIXELS*0.15\n",
    "MAX_S1_ZERO=NB_PIXELS*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.no_data_pixel_count<MAX_NO_DATA]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.s1_zero_pixel_count<MAX_S1_ZERO]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.water_ratio>0.95].shape,df[df.water_ratio<0.001].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "REarth-Parse-SWGlobal",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
